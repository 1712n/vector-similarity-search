// ⚠️ This file is auto-generated by wall-e (https://github.com/1712n/wall-e/).
// Do not edit it directly — instead, update the associated test/index.spec.* file and regenerate the code.

export interface Env {
  AI: {
    run: (
      modelName: string,
      options: { text: string[] },
    ) => Promise<{ data: number[][] }>;
  };
  HYPERDRIVE: {
    connectionString: string;
  };
}

export default {
  async scheduled(
    event: ScheduledEvent,
    env: Env,
    ctx: ExecutionContext,
  ): Promise {
    let client;

    try {
      console.log("INFO: Starting Vector Similarity Worker");

      client = new Client({
        connectionString: env.HYPERDRIVE.connectionString,
      });
      await client.connect();
      console.log("INFO: Connected to TimescaleDB");

      const messagesResult = await client.query(`
        SELECT DISTINCT um.id, um.content 
        FROM unique_messages um
        INNER JOIN message_feed mf ON um.id = mf.message_id
        WHERE um.embedding IS NULL 
        AND mf.timestamp > NOW() - INTERVAL '1 day'
        AND LENGTH(TRIM(um.content)) > 0
      `);

      const messages = messagesResult.rows;
      console.log(`INFO: Found ${messages.length} messages needing embeddings`);

      if (messages.length === 0) {
        console.log("INFO: No messages to process, exiting");
        await client.end();
        return;
      }

      const batchSize = 100;
      const modelName = "@cf/baai/bge-large-en-v1.5";
      const processedMessageIds = [];

      for (let i = 0; i < messages.length; i += batchSize) {
        const batch = messages.slice(i, i + batchSize);
        const batchNum = Math.floor(i / batchSize) + 1;
        const totalBatches = Math.ceil(messages.length / batchSize);

        try {
          console.log(
            `INFO: Processing embedding batch ${batchNum}/${totalBatches} (${batch.length} messages)`,
          );

          const texts = batch.map((msg) => msg.content);
          const embeddingResponse = await env.AI.run(modelName, {
            text: texts,
          });
          const embeddings = embeddingResponse.data;

          for (let j = 0; j < batch.length; j++) {
            const messageId = batch[j].id;
            const embedding = embeddings[j];
            const formattedEmbedding = `[${embedding.join(",")}]`;

            await client.query(
              "UPDATE unique_messages SET embedding = $1::vector WHERE id = $2",
              [formattedEmbedding, messageId],
            );
            processedMessageIds.push(messageId);
          }

          console.log(
            `INFO: Updated embeddings for batch ${batchNum}/${totalBatches}`,
          );
        } catch (error) {
          console.error(
            `ERROR: Failed to process embedding batch ${batchNum}: ${error.message}`,
          );
        }
      }

      if (processedMessageIds.length === 0) {
        console.log("INFO: No message embeddings were updated, exiting");
        await client.end();
        return;
      }

      const topicIndustryResult = await client.query(`
        SELECT topic, industry, array_agg(embedding) as reference_embeddings
        FROM synth_data_prod
        GROUP BY topic, industry
      `);

      const topicIndustryData = topicIndustryResult.rows;
      console.log(
        `INFO: Found ${topicIndustryData.length} topic-industry pairs`,
      );

      if (topicIndustryData.length === 0) {
        console.log("INFO: No topic-industry pairs found, exiting");
        await client.end();
        return;
      }

      const messageEmbeddingsResult = await client.query(
        `
        SELECT id, embedding FROM unique_messages
        WHERE id = ANY($1::int[])
      `,
        [processedMessageIds],
      );

      const messageEmbeddings = {};
      for (const row of messageEmbeddingsResult.rows) {
        messageEmbeddings[row.id] = row.embedding;
      }

      const similarityBatchSize = 50;
      let processedCount = 0;
      let totalToProcess =
        processedMessageIds.length * topicIndustryData.length;

      console.log(
        `INFO: Need to process ${totalToProcess} similarity calculations`,
      );

      for (
        let msgIndex = 0;
        msgIndex < processedMessageIds.length;
        msgIndex += similarityBatchSize
      ) {
        const messageBatch = processedMessageIds.slice(
          msgIndex,
          msgIndex + similarityBatchSize,
        );

        for (const {
          topic,
          industry,
          reference_embeddings,
        } of topicIndustryData) {
          try {
            console.log(
              `INFO: Processing similarities for ${messageBatch.length} messages, topic=${topic}, industry=${industry}`,
            );

            for (const messageId of messageBatch) {
              try {
                const messageEmbedding = messageEmbeddings[messageId];
                if (!messageEmbedding) {
                  console.log(
                    `INFO: No embedding found for message ${messageId}, skipping`,
                  );
                  continue;
                }

                let maxSimilarity = -1;
                for (const refEmbedding of reference_embeddings) {
                  const similarityResult = await client.query(
                    `
                    SELECT 1 - (($1::vector) <=> ($2::vector)) as similarity
                  `,
                    [messageEmbedding, refEmbedding],
                  );

                  const similarity = parseFloat(
                    similarityResult.rows[0].similarity,
                  );
                  maxSimilarity = Math.max(maxSimilarity, similarity);
                }

                const existingResult = await client.query(
                  `
                  SELECT id, main FROM message_scores 
                  WHERE message_id = $1 AND topic = $2 AND industry = $3
                `,
                  [messageId, topic, industry],
                );

                if (existingResult.rows.length > 0) {
                  const { id, main } = existingResult.rows[0];

                  await client.query(
                    `
                    UPDATE message_scores 
                    SET similarity = $1, 
                        main = CASE WHEN main IS NULL THEN $2 ELSE main END
                    WHERE id = $3
                  `,
                    [maxSimilarity, maxSimilarity, id],
                  );
                } else {
                  await client.query(
                    `
                    INSERT INTO message_scores (topic, industry, similarity, main, message_id)
                    VALUES ($1, $2, $3, $4, $5)
                  `,
                    [topic, industry, maxSimilarity, maxSimilarity, messageId],
                  );
                }

                processedCount++;
                if (processedCount % 100 === 0) {
                  console.log(
                    `INFO: Processed ${processedCount}/${totalToProcess} similarity calculations`,
                  );
                }
              } catch (error) {
                console.error(
                  `ERROR: Failed to process message ${messageId} for topic=${topic}, industry=${industry}: ${error.message}`,
                );
              }
            }
          } catch (error) {
            console.error(
              `ERROR: Failed to process batch for topic=${topic}, industry=${industry}: ${error.message}`,
            );
          }
        }
      }

      console.log(
        `INFO: Completed ${processedCount}/${totalToProcess} similarity calculations`,
      );
      console.log("INFO: Vector Similarity Worker completed successfully");
    } catch (error) {
      console.error(`ERROR: Vector Similarity Worker failed: ${error.message}`);
    } finally {
      if (client) {
        try {
          await client.end();
        } catch (error) {
          console.error(
            `ERROR: Failed to close database connection: ${error.message}`,
          );
        }
      }
    }
  },
};
