// ⚠️ This file is auto-generated by wall-e (https://github.com/1712n/wall-e/).
// Do not edit it directly — instead, update the associated test/index.spec.* file and regenerate the code.

import { Client } from "pg";
const MODEL = "@cf/baai/bge-base-en-v1.5";
const BATCH = 100;
export default {
  async scheduled(_evt: ScheduledEvent, env: Record<string, any>) {
    const log = (lvl: string, msg: string, ctx: Record<string, any> = {}) =>
      console.log(`${lvl} ${JSON.stringify(ctx)} ${msg}`);
    let db: Client | null = null;
    try {
      db = new Client({ connectionString: env.HYPERDRIVE.connectionString });
      await db.connect();
      log("INFO", "db_connected");
      const { rows: msgRows } = await db.query(
        `SELECT DISTINCT um.id,um.content FROM unique_messages um WHERE um.embedding IS NULL AND um.content<>'' AND EXISTS(SELECT 1 FROM message_feed mf WHERE mf.message_id=um.id AND mf.timestamp>=NOW()-INTERVAL '1 day')`,
      );
      if (!msgRows.length) {
        log("INFO", "no_messages");
        await db.end();
        return;
      }
      for (let i = 0; i < msgRows.length; i += BATCH) {
        const slice = msgRows.slice(i, i + BATCH);
        const texts = slice.map((r: any) => r.content);
        let aiResp;
        try {
          aiResp = await env.AI.run(MODEL, { text: texts });
        } catch (e) {
          log("ERROR", "ai_run_fail", { err: String(e) });
          continue;
        }
        if (!aiResp?.data || aiResp.data.length !== slice.length) {
          log("ERROR", "ai_resp_invalid");
          continue;
        }
        const vals = slice.map((r: any, j: number) => [
          `(${r.id},$${j + 1})`,
          `[${(aiResp.data[j] as number[]).join(",")}]`,
        ]);
        const placeholders = vals.map((v) => v[0]).join(","),
          embParams = vals.map((v) => v[1]);
        const updQuery = `UPDATE unique_messages AS u SET embedding=v.emb::vector FROM (VALUES ${placeholders}) AS v(id,emb) WHERE u.id=v.id`;
        try {
          await db.query(updQuery, embParams);
          log("INFO", "embeddings_updated", { count: slice.length });
        } catch (e) {
          log("ERROR", "embedding_update_fail", { err: String(e) });
        }
        for (let j = 0; j < slice.length; j++) {
          const id = slice[j].id;
          const emb = embParams[j];
          try {
            await db.query(
              `
WITH pairs AS(SELECT DISTINCT topic,industry FROM synth_data_prod),
calc AS(
SELECT p.topic,p.industry,
(SELECT sd.embedding <=> $1::vector FROM synth_data_prod sd WHERE sd.topic=p.topic AND sd.industry=p.industry ORDER BY sd.embedding <=> $1::vector LIMIT 1) AS dist FROM pairs p)
INSERT INTO message_scores(topic,industry,similarity,main,message_id)
SELECT topic,industry,1-dist,COALESCE(main,1-dist),$2 FROM calc`,
              [emb, id],
            );
          } catch (e) {
            log("ERROR", "similarity_insert_fail", { id, err: String(e) });
          }
        }
      }
      log("INFO", "run_complete", { total: msgRows.length });
    } catch (e) {
      log("ERROR", "fatal", { err: String(e) });
    } finally {
      try {
        await db?.end();
      } catch {}
    }
  },
};
