// ⚠️ This file is auto-generated by wall-e (https://github.com/1712n/wall-e/).
// Do not edit it directly — instead, update the associated test/index.spec.* file and regenerate the code.

import { Client } from "pg";
const MODEL = "@cf/baai/bge-base-en-v1.5";
const EMB_BATCH = 100;
const log = (lvl: string, stage: string, msg: string, extra = "") =>
  console[lvl === `ERROR` ? "error" : "info"](
    `VectorWorker ${lvl} stage=${stage} ${msg}${extra}`,
  );
const chunk = (a: T[], n: number) => {
  const r: T[][] = [];
  for (let i = 0; i < a.length; i += n) r.push(a.slice(i, i + n));
  return r;
};
const fetchPending = async (c: Client) => {
  const { rows } = await c.query(
    `SELECT DISTINCT um.id,um.content FROM unique_messages um JOIN message_feed mf ON mf.message_id=um.id WHERE um.embedding IS NULL AND mf.timestamp>NOW()-INTERVAL '1 day' AND LENGTH(TRIM(um.content))>0`,
  );
  return rows as { id: number; content: string }[];
};
const fetchPairs = async (c: Client) => {
  const { rows } = await c.query(
    `SELECT DISTINCT topic,industry FROM synth_data_prod`,
  );
  return rows as { topic: string; industry: string }[];
};
const processBatch = async (
  c: Client,
  env: any,
  b: { id: number; content: string }[],
  pairs: { topic: string; industry: string }[],
) => {
  const texts = b.map((v) => v.content);
  const ai = await env.AI.run(MODEL, { text: texts });
  const embeds: string[] = ai.data.map((v: number[]) => `[${v.join(",")}]`);
  const ids = b.map((v) => v.id);
  const topics = pairs.map((p) => p.topic);
  const industries = pairs.map((p) => p.industry);
  await c.query("BEGIN");
  await c.query(
    `WITH md AS(SELECT UNNEST($1::int[])id,UNNEST($2::vector[])embedding),up AS(UPDATE unique_messages u SET embedding=md.embedding FROM md WHERE u.id=md.id),pr AS(SELECT UNNEST($3::text[])topic,UNNEST($4::text[])industry),s AS(SELECT md.id message_id,pr.topic,pr.industry,(SELECT 1-(sd.embedding<=>md.embedding) FROM synth_data_prod sd WHERE sd.topic=pr.topic AND sd.industry=pr.industry ORDER BY sd.embedding<=>md.embedding LIMIT 1)similarity FROM md CROSS JOIN pr)INSERT INTO message_scores(topic,industry,similarity,main,message_id)SELECT topic,industry,similarity,COALESCE(NULL,similarity),message_id FROM s`,
    [ids, embeds, topics, industries],
  );
  await c.query("COMMIT");
};
export default {
  async scheduled(_: any, env: any) {
    const t = Date.now();
    try {
      const db = new Client({
        connectionString: env.HYPERDRIVE.connectionString,
      });
      await db.connect();
      const msgs = await fetchPending(db);
      if (!msgs.length) {
        log("INFO", "init", "no-pending");
        await db.end();
        return;
      }
      const pairs = await fetchPairs(db);
      for (const batch of chunk(msgs, EMB_BATCH)) {
        try {
          log("INFO", "batch-start", `size=${batch.length}`);
          await processBatch(db, env, batch, pairs);
          log("INFO", "batch-end", `size=${batch.length}`);
        } catch (e) {
          log("ERROR", "batch", `size=${batch.length} `, (e as Error).message);
        }
      }
      log(
        "INFO",
        "done",
        `processed=${msgs.length} elapsed=${Date.now() - t}ms`,
      );
      await db.end();
    } catch (e) {
      log("ERROR", "fatal", (e as Error).message);
    }
  },
};
