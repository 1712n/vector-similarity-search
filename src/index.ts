// ⚠️ This file is auto-generated by wall-e (https://github.com/1712n/wall-e/).
// Do not edit it directly — instead, update the associated test/index.spec.* file and regenerate the code.

import { Client } from "pg";
const MODEL = "@cf/baai/bge-m3";
const BATCH = 100;
const Q_SELECT = `
SELECT um.id,um.content
FROM unique_messages um
WHERE um.embedding IS NULL
AND um.content<>''
AND EXISTS(
 SELECT 1 FROM message_feed mf
 WHERE mf.message_id=um.id
 AND mf.timestamp>NOW()-INTERVAL '1 day')
LIMIT $1`;
export default {
  async scheduled(
    _: ScheduledController,
    env: { AI: any; HYPERDRIVE: { connectionString: string } },
  ) {
    const log = (
      l: "INFO" | "ERROR",
      m: string,
      d: Record<string, unknown> = {},
    ) => console.log(JSON.stringify({ l, m, ...d }));
    const pg = new Client({
      connectionString: env.HYPERDRIVE.connectionString,
    });
    try {
      await pg.connect();
      for (;;) {
        let rows: { id: number; content: string }[];
        try {
          rows = (await pg.query(Q_SELECT, [BATCH])).rows;
        } catch (e) {
          log("ERROR", "select_failed", { e: (e as Error).message });
          break;
        }
        if (!rows.length) {
          log("INFO", "no_messages");
          break;
        }
        const ids = rows.map((r) => r.id);
        let vecs: number[][];
        try {
          vecs = (await env.AI.run(MODEL, { text: rows.map((r) => r.content) }))
            .data;
        } catch (e) {
          log("ERROR", "ai_failed", {
            e: (e as Error).message,
            count: rows.length,
          });
          break;
        }
        const vtxt = vecs.map((v) => "[" + v.join(",") + "]");
        try {
          await pg.query("BEGIN");
          await pg.query(
            `
UPDATE unique_messages AS u
SET embedding=d.embedding
FROM(SELECT UNNEST($1::text[])::vector AS embedding,UNNEST($2::int[]) AS id)d
WHERE u.id=d.id`,
            [vtxt, ids],
          );
          await pg.query(
            `
WITH m AS(
 SELECT UNNEST($1::int[]) AS mid,UNNEST($2::text[])::vector AS emb),
p AS(SELECT DISTINCT topic,industry FROM synth_data_prod),
s AS(
 SELECT m.mid,p.topic,p.industry,
 (SELECT 1-(sd.embedding<=>m.emb)
  FROM synth_data_prod sd
  WHERE sd.topic=p.topic AND sd.industry=p.industry
  ORDER BY sd.embedding<=>m.emb
  LIMIT 1) sim
 FROM m,p)
INSERT INTO message_scores(topic,industry,main,similarity,message_id)
SELECT topic,industry,sim,sim,mid FROM s
ON CONFLICT(topic,industry,message_id)
DO UPDATE SET
 similarity=EXCLUDED.similarity,
 main=COALESCE(message_scores.main,EXCLUDED.similarity)`,
            [ids, vtxt],
          );
          await pg.query("COMMIT");
          log("INFO", "batch_done", { size: ids.length });
        } catch (e) {
          await pg.query("ROLLBACK").catch(() => {});
          log("ERROR", "db_failed", { e: (e as Error).message });
          break;
        }
      }
    } catch (e) {
      log("ERROR", "worker_crashed", { e: (e as Error).message });
    } finally {
      await pg.end().catch(() => {});
    }
  },
};
