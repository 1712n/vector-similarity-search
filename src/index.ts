// ⚠️ This file is auto-generated by wall-e (https://github.com/1712n/wall-e/).
// Do not edit it directly — instead, update the associated test/index.spec.* file and regenerate the code.

import { Client } from "pg";
const MODEL = "@cf/baai/bge-m3";
const MAX_EMBED_BATCH = 100;
const DAY_MS = 86_400_000;
const log = (
  lvl: "INFO" | "ERROR",
  stage: string,
  msg: string,
  data?: unknown,
) =>
  console.log(
    `[${lvl}]${stage}:${msg}${data ? `|${JSON.stringify(data)}` : ""}`,
  );
const chunk = (a: T[], n: number) =>
  Array.from({ length: Math.ceil(a.length / n) }, (_, i) =>
    a.slice(i * n, i * n + n),
  );
export default {
  async scheduled(_: ScheduledController, env: Env, __: ExecutionContext) {
    const stage = "worker";
    let client: Client | null = null;
    try {
      log("INFO", stage, "start");
      client = new Client({
        connectionString: env.HYPERDRIVE.connectionString,
      });
      await client.connect();
      const msgStage = "select_messages";
      try {
        const { rows: msgs } = await client.query<{
          id: number;
          content: string;
        }>(`
					SELECT um.id, um.content
					FROM unique_messages um
					JOIN message_feed mf ON mf.message_id = um.id
					WHERE um.embedding IS NULL
					  AND um.content <> ''
					  AND mf.timestamp >= NOW() - INTERVAL '1 day'
					GROUP BY um.id, um.content
					LIMIT 500
				`);
        if (!msgs.length) {
          log("INFO", msgStage, "no_messages");
          return;
        }
        log("INFO", msgStage, "messages_found", { count: msgs.length });
        const processedIds: number[] = [];
        for (const batch of chunk(msgs, MAX_EMBED_BATCH)) {
          const batchStage = `embed_${processedIds.length}_${processedIds.length + batch.length}`;
          try {
            const inputs = batch.map((b) => b.content);
            const aiResp: any = await env.AI.run(MODEL, { text: inputs });
            if (!aiResp?.data || aiResp.data.length !== batch.length)
              throw new Error("embedding_mismatch");
            const params: (number | string)[] = [];
            const valuesSql = batch
              .map((m, i) => {
                const emb = `[${aiResp.data[i].join(",")}]`;
                params.push(m.id, emb);
                return `($${i * 2 + 1}::int, $${i * 2 + 2}::vector)`;
              })
              .join(",");
            await client.query(
              `UPDATE unique_messages AS um SET embedding = v.embedding FROM (VALUES ${valuesSql}) AS v(id, embedding) WHERE um.id = v.id`,
              params,
            );
            processedIds.push(...batch.map((b) => b.id));
            log("INFO", batchStage, "embeddings_updated", {
              size: batch.length,
            });
          } catch (e) {
            log(
              "ERROR",
              batchStage,
              "embedding_fail",
              e instanceof Error ? e.message : e,
            );
          }
        }
        if (processedIds.length) {
          const scoreStage = "insert_scores";
          try {
            await client.query(
              `INSERT INTO message_scores (topic, industry, main, similarity, message_id)
							 SELECT sd.topic,
									sd.industry,
									(1 - MIN(sd.embedding <=> um.embedding))::real AS main,
									(1 - MIN(sd.embedding <=> um.embedding))::real AS similarity,
									um.id
							 FROM synth_data_prod sd
							 JOIN (SELECT id, embedding FROM unique_messages WHERE id = ANY($1::int[])) um ON TRUE
							 GROUP BY sd.topic, sd.industry, um.id`,
              [processedIds],
            );
            log("INFO", scoreStage, "scores_inserted", {
              messages: processedIds.length,
            });
          } catch (e) {
            log(
              "ERROR",
              scoreStage,
              "score_fail",
              e instanceof Error ? e.message : e,
            );
          }
        }
      } catch (e) {
        log(
          "ERROR",
          msgStage,
          "select_fail",
          e instanceof Error ? e.message : e,
        );
      }
    } catch (e) {
      log("ERROR", stage, "init_fail", e instanceof Error ? e.message : e);
    } finally {
      try {
        await client?.end();
      } catch (_) {}
      log("INFO", stage, "end");
    }
  },
};
type Env = {
  AI: any;
  HYPERDRIVE: { connectionString: string };
};
