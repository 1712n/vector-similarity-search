// ⚠️ This file is auto-generated by wall-e (https://github.com/1712n/wall-e/).
// Do not edit it directly — instead, update the associated test/index.spec.* file and regenerate the code.

import { Client } from "pg";

interface Env {
  AI: {
    run: (
      modelName: string,
      options: { texts: string[] },
    ) => Promise<{ data: number[][] }>;
  };
  HYPERDRIVE: {
    connectionString: string;
  };
}

export default {
  async scheduled(
    event: ScheduledEvent,
    env: Env,
    ctx: ExecutionContext,
  ): Promise {
    const client = new Client({
      connectionString: env.HYPERDRIVE.connectionString,
    });

    try {
      await client.connect();
      console.log("INFO: Starting vector similarity worker");

      // 1. Select messages that need embeddings (less than 1 day old with null embedding)
      const messagesResult = await client.query(`
        SELECT DISTINCT um.id, um.content 
        FROM unique_messages um
        JOIN message_feed mf ON um.id = mf.message_id
        WHERE um.embedding IS NULL 
        AND um.content != ''
        AND mf.timestamp > NOW() - INTERVAL '1 day'
      `);

      const messages = messagesResult.rows;
      console.log(`INFO: Found ${messages.length} messages needing embeddings`);

      if (messages.length === 0) return;

      // 2. Generate embeddings in batches of 100
      const batchSize = 100;
      const messageEmbeddings = [];
      const modelName = "@cf/baai/bge-base-en-v1.5";

      for (let i = 0; i < messages.length; i += batchSize) {
        try {
          const batch = messages.slice(i, i + batchSize);
          const texts = batch.map((message) => message.content);

          console.log(
            `INFO: Generating embeddings batch ${Math.floor(i / batchSize) + 1}/${Math.ceil(messages.length / batchSize)}`,
          );
          const resp = await env.AI.run(modelName, { texts });

          for (let j = 0; j < batch.length; j++) {
            messageEmbeddings.push({
              id: batch[j].id,
              embedding: resp.data[j],
              formattedEmbedding: `[${resp.data[j].join(",")}]`,
            });
          }
        } catch (error) {
          console.error(`ERROR: Embedding generation failed: ${error.message}`);
          throw error;
        }
      }

      // 3. Fetch all topic-industry pairs and existing scores
      const [topicIndustryResult, existingScoresResult] = await Promise.all([
        client.query(`SELECT topic, industry, embedding FROM synth_data_prod`),
        client.query(
          `
          SELECT message_id, topic, industry, main 
          FROM message_scores 
          WHERE message_id = ANY($1)
        `,
          [messageEmbeddings.map((m) => m.id)],
        ),
      ]);

      const topicIndustryPairs = topicIndustryResult.rows;
      console.log(
        `INFO: Found ${topicIndustryPairs.length} topic-industry pairs`,
      );

      // Create a map of existing scores for quick lookup
      const existingScoresMap = {};
      existingScoresResult.rows.forEach((score) => {
        const key = `${score.message_id}-${score.topic}-${score.industry}`;
        existingScoresMap[key] = score.main;
      });

      // 4. Start transaction for all database operations
      await client.query("BEGIN");

      try {
        // Update message embeddings
        for (const { id, formattedEmbedding } of messageEmbeddings) {
          await client.query(
            "UPDATE unique_messages SET embedding = $1::vector WHERE id = $2",
            [formattedEmbedding, id],
          );
        }

        // Calculate similarities and prepare insert/update batches
        const newScores = [];
        const updatedScores = [];

        for (const { id: messageId, formattedEmbedding } of messageEmbeddings) {
          for (const {
            topic,
            industry,
            embedding: pairEmbedding,
          } of topicIndustryPairs) {
            try {
              const similarityResult = await client.query(
                `
                SELECT 1 - ($1::vector <=> $2::vector) AS similarity
              `,
                [formattedEmbedding, pairEmbedding],
              );

              const similarity = similarityResult.rows[0].similarity;
              const key = `${messageId}-${topic}-${industry}`;

              if (key in existingScoresMap) {
                updatedScores.push([similarity, messageId, topic, industry]);
              } else {
                newScores.push([
                  topic,
                  industry,
                  similarity,
                  similarity,
                  messageId,
                ]);
              }
            } catch (error) {
              console.error(
                `ERROR: Similarity calculation failed for message ${messageId}, topic ${topic}: ${error.message}`,
              );
              throw error;
            }
          }
        }

        // Insert new scores
        for (const scoreData of newScores) {
          await client.query(
            `
            INSERT INTO message_scores (topic, industry, main, similarity, message_id)
            VALUES ($1, $2, $3, $4, $5)
          `,
            scoreData,
          );
        }

        // Update existing scores
        for (const [similarity, messageId, topic, industry] of updatedScores) {
          await client.query(
            `
            UPDATE message_scores
            SET similarity = $1, main = COALESCE(main, $1)
            WHERE message_id = $2 AND topic = $3 AND industry = $4
          `,
            [similarity, messageId, topic, industry],
          );
        }

        await client.query("COMMIT");
        console.log(
          `INFO: Updated ${messageEmbeddings.length} embeddings, inserted ${newScores.length} scores, updated ${updatedScores.length} scores`,
        );
      } catch (error) {
        await client.query("ROLLBACK");
        console.error(`ERROR: Transaction failed: ${error.message}`);
        throw error;
      }

      console.log("INFO: Vector similarity worker completed successfully");
    } catch (error) {
      console.error(`ERROR: Worker execution failed: ${error.message}`);
      throw error;
    } finally {
      await client
        .end()
        .catch((err) =>
          console.error(`ERROR: Database disconnect failed: ${err.message}`),
        );
    }
  },
};
