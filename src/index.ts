// ⚠️ This file is auto-generated by wall-e (https://github.com/1712n/wall-e/).
// Do not edit it directly — instead, update the associated test/index.spec.* file and regenerate the code.

import { Client } from "pg";
export interface Env {
  AI: Ai;
  HYPERDRIVE: Hyperdrive;
}
export default {
  async scheduled(
    controller: ScheduledController,
    env: Env,
    ctx: ExecutionContext,
  ): Promise {
    const client = new Client({
      connectionString: env.HYPERDRIVE.connectionString,
    });
    try {
      console.info("INFO:Starting vector similarity worker");
      await client.connect();
      const messagesResult = await client.query(
        `SELECT DISTINCT u.id,u.content FROM unique_messages u INNER JOIN message_feed m ON u.id=m.message_id WHERE u.embedding IS NULL AND u.content IS NOT NULL AND u.content!='' AND m.timestamp>NOW()-INTERVAL '1 day'`,
      );
      if (messagesResult.rows.length === 0) {
        console.info("INFO:No messages to process");
        return;
      }
      console.info(`INFO:Processing ${messagesResult.rows.length} messages`);
      const topicsResult = await client.query(
        `SELECT DISTINCT topic,industry FROM synth_data_prod`,
      );
      if (topicsResult.rows.length === 0) {
        console.error("ERROR:No topic-industry pairs found");
        return;
      }
      console.info(
        `INFO:Found ${topicsResult.rows.length} topic-industry pairs`,
      );
      const batchSize = 100;
      const allEmbeddings = new Map<number, number[]>();
      for (let i = 0; i < messagesResult.rows.length; i += batchSize) {
        const batch = messagesResult.rows.slice(
          i,
          Math.min(i + batchSize, messagesResult.rows.length),
        );
        try {
          console.info(
            `INFO:Generating embeddings batch ${Math.floor(i / batchSize) + 1}`,
          );
          const texts = batch.map((row) => row.content);
          const response = await env.AI.run("@cf/baai/bge-m3", { text: texts });
          batch.forEach((row, idx) => {
            if (response.data && response.data[idx]) {
              allEmbeddings.set(row.id, response.data[idx]);
            }
          });
        } catch (err) {
          console.error(
            `ERROR:Embedding batch ${Math.floor(i / batchSize) + 1} failed:${err}`,
          );
        }
      }
      if (allEmbeddings.size === 0) {
        console.error("ERROR:No embeddings generated");
        return;
      }
      await client.query("BEGIN");
      try {
        const updateEmbeddingsQuery = `UPDATE unique_messages SET embedding=data.embedding::vector FROM (VALUES ${Array.from(
          allEmbeddings.entries(),
        )
          .map((_, idx) => `($${idx * 2 + 1},$${idx * 2 + 2}::vector)`)
          .join(",")}) AS data(id,embedding) WHERE unique_messages.id=data.id`;
        const embeddingValues: any[] = [];
        for (const [id, embedding] of allEmbeddings) {
          embeddingValues.push(id, `[${embedding.join(",")}]`);
        }
        await client.query(updateEmbeddingsQuery, embeddingValues);
        console.info(`INFO:Updated ${allEmbeddings.size} embeddings`);
        const scoreValues: any[] = [];
        let scoreParams: string[] = [];
        let paramCount = 0;
        for (const [messageId, embedding] of allEmbeddings) {
          const embeddingStr = `[${embedding.join(",")}]`;
          for (const topicRow of topicsResult.rows) {
            try {
              const simResult = await client.query(
                `SELECT 1-(embedding<=>$1::vector)as similarity FROM synth_data_prod WHERE topic=$2 AND industry=$3 ORDER BY embedding<=>$1::vector LIMIT 1`,
                [embeddingStr, topicRow.topic, topicRow.industry],
              );
              if (simResult.rows.length > 0) {
                const similarity = simResult.rows[0].similarity;
                scoreParams.push(
                  `($${paramCount + 1},$${paramCount + 2},$${paramCount + 3},$${paramCount + 4})`,
                );
                scoreValues.push(
                  messageId,
                  topicRow.topic,
                  topicRow.industry,
                  similarity,
                );
                paramCount += 4;
              }
            } catch (err) {
              console.error(
                `ERROR:Similarity calc failed msg:${messageId} topic:${topicRow.topic} industry:${topicRow.industry}:${err}`,
              );
            }
          }
        }
        if (scoreValues.length > 0) {
          const insertScoresQuery = `INSERT INTO message_scores(message_id,topic,industry,similarity)VALUES ${scoreParams.join(",")} ON CONFLICT(message_id,topic,industry)DO UPDATE SET similarity=EXCLUDED.similarity`;
          await client.query(insertScoresQuery, scoreValues);
          console.info(
            `INFO:Inserted/updated ${scoreParams.length} similarity scores`,
          );
          await client.query(
            `UPDATE message_scores SET main=similarity WHERE main IS NULL AND similarity IS NOT NULL`,
          );
          console.info("INFO:Updated main scores where null");
        }
        await client.query("COMMIT");
        console.info("INFO:Transaction committed successfully");
      } catch (err) {
        await client.query("ROLLBACK");
        console.error(`ERROR:Transaction failed:${err}`);
        throw err;
      }
    } catch (err) {
      console.error(`ERROR:Worker execution failed:${err}`);
      throw err;
    } finally {
      await client.end();
    }
  },
};
